{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"18bd689fe4f9477da090d7d29451850b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49c742a5d0204aa6958ba264b1c42e49","IPY_MODEL_589605db19734834adc9789afd680613","IPY_MODEL_2f36db1ef0944f6d9be2c36e17c1fea6"],"layout":"IPY_MODEL_488bc199bbf442ce88c67177ce4e3f68"}},"49c742a5d0204aa6958ba264b1c42e49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b169a0bd638143e99860c6691d10faff","placeholder":"​","style":"IPY_MODEL_9539f65883eb4b5d89c1503c30a049b7","value":"Fetching 5 files: 100%"}},"589605db19734834adc9789afd680613":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6102ac087d7f4ea4b78d5f78a776c470","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0136b10f7654ccfa3e8db798e6f7127","value":5}},"2f36db1ef0944f6d9be2c36e17c1fea6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93c25a17daa84223bd112927658e8d7f","placeholder":"​","style":"IPY_MODEL_e379b3df38be45c5ad8943beace5c50e","value":" 5/5 [00:00&lt;00:00, 453.40it/s]"}},"488bc199bbf442ce88c67177ce4e3f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b169a0bd638143e99860c6691d10faff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9539f65883eb4b5d89c1503c30a049b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6102ac087d7f4ea4b78d5f78a776c470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0136b10f7654ccfa3e8db798e6f7127":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93c25a17daa84223bd112927658e8d7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e379b3df38be45c5ad8943beace5c50e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65da0782f70c453cada2bd5ea8ebe0f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0db39a860fa2403c95e3d864050e241c","IPY_MODEL_498ceeaa84ad42749ad10e4c885cc83b","IPY_MODEL_d10cdf79189f4b54946bfd5c9d5e229e"],"layout":"IPY_MODEL_4804c54639914da2ab8287fd4d3b6caf"}},"0db39a860fa2403c95e3d864050e241c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_306968cc03f0436d9e9c01c263bc12cd","placeholder":"​","style":"IPY_MODEL_5d22d9657c6e41b586b0867a521c9080","value":"Loading checkpoint shards: 100%"}},"498ceeaa84ad42749ad10e4c885cc83b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f08a93f1be74e449eb9200af82fefda","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_909097ab583f4ae98819db3ec70eaf67","value":8}},"d10cdf79189f4b54946bfd5c9d5e229e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f84e6f6f659431e80d5221de8891b3d","placeholder":"​","style":"IPY_MODEL_ee322f9f62394abd9d60f415aad15238","value":" 8/8 [00:05&lt;00:00,  1.54it/s]"}},"4804c54639914da2ab8287fd4d3b6caf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"306968cc03f0436d9e9c01c263bc12cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d22d9657c6e41b586b0867a521c9080":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f08a93f1be74e449eb9200af82fefda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"909097ab583f4ae98819db3ec70eaf67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f84e6f6f659431e80d5221de8891b3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee322f9f62394abd9d60f415aad15238":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["# Hybrid Search RAG Pipeline in LlamaIndex\n","\n","This notebook demonstrates how to build a Hybrid Search Retrieval Augmented Generation (RAG) pipeline using Open Source Models using `HuggingFace` and `FastEmbeddings` with `llama-index`\n","\n","## Setup\n","\n","First, install the necessary packages:\n","\n","\n"],"metadata":{"id":"_lkA3Z5YYbOt"}},{"cell_type":"markdown","source":["## Install Necessary Packages and save Access Tokens:"],"metadata":{"id":"hP33L02SwkuN"}},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"wbL7Xn-_vGhT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720546909321,"user_tz":180,"elapsed":55782,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"005ac625-c0d8-4369-d369-36488bd3eb0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-vector-stores-chroma\n","  Downloading llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl (5.0 kB)\n","Collecting chromadb<0.6.0,>=0.4.0 (from llama-index-vector-stores-chroma)\n","  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-chroma)\n","  Downloading llama_index_core-0.10.53.post1-py3-none-any.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.2.1)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.8.0)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.25.2)\n","Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.12.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.66.4)\n","Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.64.1)\n","Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.12.3)\n","Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (8.4.2)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.0.1)\n","Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.27.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting SQLAlchemy[asyncio]>=1.4.49 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.6.1)\n","Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.8.1)\n","Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading openai-1.35.11-py3-none-any.whl (328 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.4/328.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (10.4.0)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.14.1)\n","Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (23.2.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (24.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.1.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.0.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.1.4)\n","Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2024.6.2)\n","Collecting httpcore==1.* (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.0.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.5.15)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.12.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.7.0)\n","Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.63.2)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n","Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n","Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (67.7.2)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.3.2)\n","Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.23.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (13.7.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m502.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.2.1)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.15.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.19.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.18.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.1.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.0)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=cf6be5d3c4793fbce3c2d09ee9adab20de6d066022f7f1f4852ca6cc809a2367\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, ujson, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, multidict, marshmallow, importlib-metadata, humanfriendly, httptools, h11, greenlet, frozenlist, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, async-timeout, asgiref, yarl, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, SQLAlchemy, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpcore, email_validator, coloredlogs, aiosignal, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, dataclasses-json, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, llama-cloud, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, llama-index-core, fastapi, chromadb, llama-index-vector-stores-chroma\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.6.4\n","    Uninstalling importlib-metadata-4.6.4:\n","      Successfully uninstalled importlib-metadata-4.6.4\n","Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 asgiref-3.8.1 async-timeout-4.0.3 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 frozenlist-1.4.1 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.1.0 kubernetes-30.1.0 llama-cloud-0.0.6 llama-index-core-0.10.53.post1 llama-index-vector-stores-chroma-0.1.10 marshmallow-3.21.3 mmh3-4.1.0 monotonic-1.6 multidict-6.0.5 mypy-extensions-1.0.0 onnxruntime-1.18.1 openai-1.35.11 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 tiktoken-0.7.0 typing-inspect-0.9.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0 yarl-1.9.4\n","Collecting llama-index\n","  Downloading llama_index-0.10.53-py3-none-any.whl (6.8 kB)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n","Requirement already satisfied: llama-index-core==0.10.53.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.53.post1)\n","Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n","  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n","Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.2.3-py3-none-any.whl (9.2 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n","  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n","  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_readers_file-0.1.29-py3-none-any.whl (38 kB)\n","Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (3.9.5)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (2024.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.25.2)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.35.11)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (10.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (8.4.2)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (4.12.2)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.53.post1->llama-index) (1.14.1)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n","Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n","  Downloading llama_parse-0.4.6-py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.8.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.53.post1->llama-index) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (2024.5.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.53.post1->llama-index) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.53.post1->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.53.post1->llama-index) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.53.post1->llama-index) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.53.post1->llama-index) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (3.21.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.53.post1->llama-index) (1.2.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (24.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.53.post1->llama-index) (1.16.0)\n","Installing collected packages: striprtf, pypdf, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","Successfully installed llama-index-0.10.53 llama-index-agent-openai-0.2.8 llama-index-cli-0.1.12 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.25 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.29 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.6 pypdf-4.2.0 striprtf-0.0.26\n","Collecting llama-index-embeddings-fastembed\n","  Downloading llama_index_embeddings_fastembed-0.1.4-py3-none-any.whl (2.7 kB)\n","Collecting fastembed<0.3.0,>=0.2.2 (from llama-index-embeddings-fastembed)\n","  Downloading fastembed-0.2.7-py3-none-any.whl (27 kB)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-fastembed) (0.10.53.post1)\n","Collecting huggingface-hub<0.21,>=0.20 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n","  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting loguru<0.8.0,>=0.7.2 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n","  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.25.2)\n","Collecting onnx<2.0.0,>=1.15.0 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n","  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.18.1)\n","Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.10/dist-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (2.31.0)\n","Collecting tokenizers<0.16,>=0.15 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.10/dist-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (4.66.4)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.9.5)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.8.1)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.35.11)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (10.4.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (8.4.2)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.7.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (4.12.2)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.14.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21,>=0.20->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (3.15.4)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21,>=0.20->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (24.1)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.8.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.5.15)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (3.20.3)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (24.3.25)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.12.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.21.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.2.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.16.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (10.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.3.0)\n","Installing collected packages: onnx, loguru, huggingface-hub, tokenizers, fastembed, llama-index-embeddings-fastembed\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.23.4\n","    Uninstalling huggingface-hub-0.23.4:\n","      Successfully uninstalled huggingface-hub-0.23.4\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.41.2 requires huggingface-hub<1.0,>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\n","transformers 4.41.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fastembed-0.2.7 huggingface-hub-0.20.3 llama-index-embeddings-fastembed-0.1.4 loguru-0.7.2 onnx-1.16.1 tokenizers-0.15.2\n"]}],"source":["!pip install llama-index-vector-stores-chroma\n","!pip install llama-index\n","!pip install llama-index-embeddings-fastembed"]},{"cell_type":"code","source":["#!pip install llama-index-llms-huggingface-api\n","!pip install llama-index-llms-huggingface"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deFM9GXE0-FU","outputId":"62869d78-a4f0-4fab-cd30-e2f988000833","executionInfo":{"status":"ok","timestamp":1720547056684,"user_tz":180,"elapsed":6204,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-llms-huggingface\n","  Downloading llama_index_llms_huggingface-0.2.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.4)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.41 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.10.53.post1)\n","Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n","  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.0+cpu)\n","Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.9.5)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.8)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.25.2)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.35.11)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (10.4.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.4.2)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.7.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.14.1)\n","Requirement already satisfied: pydantic<3,>2 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\n","Collecting tokenizers<0.20,>=0.19 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.3)\n","Collecting accelerate>=0.21.0 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n","  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (4.0.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.2)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.7.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.21.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.1)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.16.0)\n","Installing collected packages: tokenizers, text-generation, accelerate, llama-index-llms-huggingface\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastembed 0.2.7 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.23.4 which is incompatible.\n","fastembed 0.2.7 requires tokenizers<0.16,>=0.15, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.32.1 llama-index-llms-huggingface-0.2.4 text-generation-0.7.0 tokenizers-0.19.1\n"]}]},{"cell_type":"markdown","source":["## Set Up Hugging Face API Token"],"metadata":{"id":"mZlvYARWY2Xh"}},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","# HUGGINGFACEHUB_API_TOKEN = getpass(\"API:\")\n","\n","# # Set the API token in the environment variable\n","# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"],"metadata":{"id":"vjaL2G2fxspm","executionInfo":{"status":"ok","timestamp":1720547005287,"user_tz":180,"elapsed":278,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pyG3ws92l9xg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load and Split Medical Documents:\n","\n"],"metadata":{"id":"_e_pzRXAxN7g"}},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","\n","documents = SimpleDirectoryReader(\"data\").load_data()"],"metadata":{"id":"FTILzji8xSXO","executionInfo":{"status":"ok","timestamp":1720547553416,"user_tz":180,"elapsed":242,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Set Up FastEmbeddings Embeddings and HuggingFace LLM\n","\n"],"metadata":{"id":"DBWBD_tPxeMH"}},{"cell_type":"code","source":["from llama_index.embeddings.fastembed import FastEmbedEmbedding\n","# define embedding function\n","embed_model = FastEmbedEmbedding(model_name=\"thenlper/gte-large\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["18bd689fe4f9477da090d7d29451850b","49c742a5d0204aa6958ba264b1c42e49","589605db19734834adc9789afd680613","2f36db1ef0944f6d9be2c36e17c1fea6","488bc199bbf442ce88c67177ce4e3f68","b169a0bd638143e99860c6691d10faff","9539f65883eb4b5d89c1503c30a049b7","6102ac087d7f4ea4b78d5f78a776c470","f0136b10f7654ccfa3e8db798e6f7127","93c25a17daa84223bd112927658e8d7f","e379b3df38be45c5ad8943beace5c50e"]},"collapsed":true,"id":"RBh-3yEHbLEs","outputId":"f8b13d91-e777-44ea-b62e-529053e765cb","executionInfo":{"status":"ok","timestamp":1720547558985,"user_tz":180,"elapsed":3476,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18bd689fe4f9477da090d7d29451850b"}},"metadata":{}}]},{"cell_type":"code","source":["# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n","\n","# llm = HuggingFaceInferenceAPI(\n","#     model_name=\"HuggingFaceH4/zephyr-7b-alpha\", token=HUGGINGFACEHUB_API_TOKEN\n","# )\n","from llama_index.core import PromptTemplate\n","MODEL = \"HuggingFaceH4/zephyr-7b-alpha\"\n","system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n","- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n","- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n","- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n","- StableLM will refuse to participate in anything that could harm a human.\n","\"\"\"\n","\n","# This will wrap the default prompts that are internal to llama-index\n","query_wrapper_prompt = PromptTemplate(\"<|USER|>{query_str}<|ASSISTANT|>\")\n","\n","from llama_index.llms.huggingface import HuggingFaceLLM\n","\n","llm = HuggingFaceLLM(\n","    tokenizer_name=MODEL,\n","    model_name=MODEL,\n","    query_wrapper_prompt=query_wrapper_prompt,\n","    tokenizer_kwargs={\"max_length\": 4096},\n",")\n","\n","# llm = HuggingFaceLLM(\n","#     context_window=4096,\n","#     max_new_tokens=256,\n","#     generate_kwargs={\"temperature\": 0.7, \"do_sample\": False},\n","#     system_prompt=system_prompt,\n","#     query_wrapper_prompt=query_wrapper_prompt,\n","#     tokenizer_name=\"StabilityAI/stablelm-tuned-alpha-3b\",\n","#     model_name=\"StabilityAI/stablelm-tuned-alpha-3b\",\n","#     device_map=\"auto\",\n","#     stopping_ids=[50278, 50279, 50277, 1, 0],\n","#     tokenizer_kwargs={\"max_length\": 4096},\n","#     # uncomment this if using CUDA to reduce memory usage\n","#     # model_kwargs={\"torch_dtype\": torch.float16}\n","# )\n","\n","from llama_index.core import set_global_tokenizer\n","from transformers import AutoTokenizer\n","\n","set_global_tokenizer(\n","    AutoTokenizer.from_pretrained(MODEL).encode\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"metadata":{"id":"g8fOUayb0ncW","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["65da0782f70c453cada2bd5ea8ebe0f9","0db39a860fa2403c95e3d864050e241c","498ceeaa84ad42749ad10e4c885cc83b","d10cdf79189f4b54946bfd5c9d5e229e","4804c54639914da2ab8287fd4d3b6caf","306968cc03f0436d9e9c01c263bc12cd","5d22d9657c6e41b586b0867a521c9080","1f08a93f1be74e449eb9200af82fefda","909097ab583f4ae98819db3ec70eaf67","8f84e6f6f659431e80d5221de8891b3d","ee322f9f62394abd9d60f415aad15238"]},"executionInfo":{"status":"ok","timestamp":1720548945492,"user_tz":180,"elapsed":6572,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"18daf6be-c313-41ef-e387-d73132c439b3"},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65da0782f70c453cada2bd5ea8ebe0f9"}},"metadata":{}}]},{"cell_type":"code","source":["chat = [\n","  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n","]\n","print(tokenizer.apply_chat_template(chat, tokenize=False))\n","llm.complete(tokenizer.apply_chat_template(chat, tokenize=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fD2C5OahqBZt","executionInfo":{"status":"ok","timestamp":1720549023404,"user_tz":180,"elapsed":10097,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"0347a0fc-7428-488d-cf01-78227aeb9bac"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["<|user|>\n","Hello, how are you?</s>\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["CompletionResponse(text=\"\\nI do not have feelings or emotions, but i'm programmed to respond to your inquiries and provide you with helpful information. how can i assist you today?\", additional_kwargs={}, raw={'model_output': tensor([[    1,   523, 28766, 11123, 28766,  3409, 28766,  1838, 28766, 28767,\n","            13, 16230, 28725,   910,   460,   368, 28804,     2, 28705,    13,\n","         28789, 28766,  4816,  8048, 12738, 28766, 28767,    13, 28737,   511,\n","           459,   506,  9388,   442, 13855, 28725,   562,   613, 28742, 28719,\n","          2007,  1591,   298,  9421,   298,   574,   297, 10851,   497,   304,\n","          3084,   368,   395, 10865,  1871, 28723,   910,   541,   613,  6031,\n","           368,  3154, 28804,     2]])}, logprobs=None, delta=None)"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["## Define LLM and Embedding in Settings\n","\n","By default LlamaIndex uses OpenAI, so we need to override the settings"],"metadata":{"id":"lt2LNbAP0RSr"}},{"cell_type":"code","source":["from llama_index.core import Settings\n","\n","Settings.llm = llm\n","\n","Settings.embed_model = embed_model"],"metadata":{"id":"dVzdX-ZG0ZUq","executionInfo":{"status":"ok","timestamp":1720549037337,"user_tz":180,"elapsed":411,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["## Create Vectorstore with Chroma"],"metadata":{"id":"gDMDOe_IZCbq"}},{"cell_type":"code","source":["from llama_index.vector_stores.chroma import ChromaVectorStore\n","from llama_index.core import StorageContext\n","import chromadb"],"metadata":{"id":"7yXVxilldzhi","executionInfo":{"status":"ok","timestamp":1720548268684,"user_tz":180,"elapsed":2,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["## Index your document\n","\n","First we save the data in disk\n","- Create a Persist directory where the data will be stored\n","- Define a unique collection for each index.\n","- Store the data in StorageContext"],"metadata":{"id":"fFZBmh2lz-eC"}},{"cell_type":"code","source":["!rm -rf ./chroma_db"],"metadata":{"id":"WpJbrEpZtvNH","executionInfo":{"status":"ok","timestamp":1720549050863,"user_tz":180,"elapsed":262,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["db = chromadb.PersistentClient(path=\"./chroma_db_v2\")\n","chroma_collection = db.get_or_create_collection(\"quickstart\")\n","vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)"],"metadata":{"id":"XnDOVfXLz96w","executionInfo":{"status":"ok","timestamp":1720549087103,"user_tz":180,"elapsed":728,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["db.list_collections()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRBWZbOGoI6A","executionInfo":{"status":"ok","timestamp":1720549088643,"user_tz":180,"elapsed":283,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"f23a05f3-a029-49f0-e312-ff13d34c9d81"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<chromadb.api.models.Collection.Collection at 0x7c8977108580>]"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["index = VectorStoreIndex.from_documents(\n","    documents, storage_context=storage_context, embed_model=embed_model\n",")"],"metadata":{"id":"yIvddPFz1MQq","executionInfo":{"status":"ok","timestamp":1720549096325,"user_tz":180,"elapsed":6543,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["index.as_query_engine().query(\"summerize Tarun's role at AI Planet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-T0xarien4Oq","executionInfo":{"status":"ok","timestamp":1720549150552,"user_tz":180,"elapsed":50925,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"d479e42a-d796-4489-f75c-2d9766ea85ec"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["Response(response=\"\\nTarun is a software developer at AI Planet, where he works on developing AI-based solutions for various industries. He is passionate about using technology to solve real-world problems and is constantly exploring new ways to improve the company's products. Tarun is also a mentor and coach to other developers, helping them to improve their skills and advance their careers. Overall, Tarun is a key member of the AI Planet team, contributing to the company's growth and success.\", source_nodes=[NodeWithScore(node=TextNode(id_='81140a75-2458-410e-80d9-29fce7ac0183', embedding=None, metadata={'page_label': '10', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='53d587ca-f3e5-441b-a726-186ff46ddf67', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '10', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}, hash='410ff647910f9b80773e3351ece6c253b3b161eb4c3b09b97683c55602d26ff5')}, text='10/KALEIDOSCOPE\\nLanguage W ork\\nA.Vocabulary\\nLook up the meanings of the following phrases under ‘dream’\\nand ‘sell’ in the dictionary\\ndream         sell\\ndream on sell-by date\\ndream something away selling-point\\n(not) dream of doing something sell-out\\ndream something up selling price\\nlook like a dream seller’s market\\nB.Grammar: Emphasis\\nRead this sentence carefully\\nOne morning  at nine o’clock, while we were having\\nbreakfast on the terrace of the Havana Riviera Hotel\\nunder a bright sun, a huge wave picked up several\\ncars that were driving down the avenue along the\\nseawall or parked on the pavement, and embedded\\none of them in the side of the hotel.\\nThe position of a word, phrase or an idea within a sentence\\nusually indicates the emphasis it receives. Generally, the most\\nemphatic place in the sentence is its  end;  the next most\\nemphatic is its beginning; and the least emphatic, its middle.\\nIn the sentence above the most important fact is that the huge\\nwave embedded one of the cars in one side of the hotel.\\nThe other details of time and place are given at the beginning.\\nThe general statement of the ‘huge wave picking up several\\ncars’ precedes the particular car which is pertinent to the theme\\nof the story.\\nLet us rewrite th e sentence, beginning with ‘a huge wave’ and\\nthe first part following ‘hotel’ and  notice the difference in the\\neffect.\\nA huge wave picked up several cars that were driving\\ndown the avenue along the seawall or parked on the\\npavement, and embedded one of them in the side of\\nthe hotel, one morning  at nine o’clock, while we were\\nhaving breakfast on the terrace of the Havana Riviera\\nHotel under a bright sun.\\nRationalised 2023-24', mimetype='text/plain', start_char_idx=0, end_char_idx=1669, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5937510731967687), NodeWithScore(node=TextNode(id_='5e650bfe-df7b-40d3-b1fb-2dd6cf023e2b', embedding=None, metadata={'page_label': '6', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='47f02c6d-69a9-460a-a910-126566e8e10c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '6', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}, hash='f0d1d3c59c387024420ac72452ca465b6fbe76e6bac3ed83e3570e395ed1aae3')}, text='6/KALEIDOSCOPE\\nStop and ThinkStop and ThinkStop and ThinkStop and ThinkStop and Think\\n1.How did the author recognise the lady who was\\nextricated from the car encrusted in the wall of Havana\\nRiviera Hotel after the storm?\\n2.Why did the author leave Vienna never to return\\nagain?\\nBefore the disaster in Havana, I had seen Frau Frieda\\nin Barcelona in so unexpected and fortuitous a way that it\\nseemed a mystery to me. It happened on the day Pablo\\nNeruda stepped on Spanish soil for the first time since the\\nCivil W ar, on a stopover during a long sea voyage to\\nValparaiso. He spent a mor ning with us hunting big game\\nin the second-hand bookstores, and at Porter he bought\\nan old, dried-out volume with a torn binding for which he\\npaid what would have been his salary for two months at\\nthe consulate in Rangoon. He moved through the crowd\\nlike an invalid elephant, with a child’s curiosity in the\\ninner workings of each thing he saw, for the world appeared\\nto him as an immense wind-up toy with which life invented\\nitself.\\nI have never known anyone closer to the idea one has\\nof a Renaissance pope: He was gluttonous and refined.\\nEven against his will, he always presided at the table.\\nMatilde, his wife, would put a bib around his neck that\\nbelonged in a barbershop rather than a dining room, but it\\nwas the only way to keep him from taking a bath in sauce.\\nThat day at Carvalleiras was typical. He ate three whole\\nlobsters, dissecting them with a surgeon’s skill, and at the\\nsame time devoured everyone else’s plate with his eyes\\nand tasted a little from each with a delight that made the\\ndesire to eat contagious: clams from Galicia, mussels from\\nCantabria, prawns from Alicante, sea cucumbers from the\\nCosta Brava. In the meantime, like the French, he spoke\\nof nothing but other culinary delicacies, in particular the\\nprehistoric shellfish of Chile, which he carried in his heart.\\nAll at once he stopped eating, tuned his lobster’s antennae,\\nand said to me in a very quiet voice:\\n‘There’s someone behind me who won’t stop looking at\\nme.’\\nRationalised 2023-24', mimetype='text/plain', start_char_idx=0, end_char_idx=2059, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5909071546504369)], metadata={'81140a75-2458-410e-80d9-29fce7ac0183': {'page_label': '10', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}, '5e650bfe-df7b-40d3-b1fb-2dd6cf023e2b': {'page_label': '6', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-07-09', 'last_modified_date': '2024-07-09'}})"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["## Load the index\n","\n","Notice, when you load, we don't use `documents`"],"metadata":{"id":"NXbNAQJ41Nv5"}},{"cell_type":"code","source":["db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n","chroma_collection = db2.get_or_create_collection(\"quickstart\")\n","vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n","index = VectorStoreIndex.from_vector_store(\n","    vector_store,\n","    embed_model=embed_model,\n",")"],"metadata":{"id":"sKSkmSnkwKpl","executionInfo":{"status":"ok","timestamp":1720549150552,"user_tz":180,"elapsed":3,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["query_engine = index.as_query_engine()\n","response = query_engine.query(\"summerize Tarun's role at AI Planet\")"],"metadata":{"id":"wcBD-4oVq8Iq","outputId":"861bf5b0-89c1-4d48-894f-dc53dcc39980","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720549172719,"user_tz":180,"elapsed":22169,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["response.response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"PIBlobfA1nQT","outputId":"4b2fdca9-d580-41c1-9f03-084159635e7f","executionInfo":{"status":"ok","timestamp":1720549172720,"user_tz":180,"elapsed":10,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}}},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nTarun is a software developer at AI Planet, where he works on developing AI-based solutions for various industries. He is also involved in research and development of new AI technologies and algorithms.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["response = query_engine.query(\"summarize Loscalzo Jonathan's role at AI Planet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFYj89P_sq1-","executionInfo":{"status":"ok","timestamp":1720549296996,"user_tz":180,"elapsed":43936,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"4abd1f71-4a08-4aa1-9f28-bf0b4e99d806"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["response.response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"VD36-1VLuh5W","executionInfo":{"status":"ok","timestamp":1720549297882,"user_tz":180,"elapsed":3,"user":{"displayName":"Jonathan Loscalzo","userId":"01585398269152205627"}},"outputId":"310d1573-f678-4f7e-b3be-33c1303374f7"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nLoscalzo Jonathan is a co-founder and CEO of AI Planet, a company that provides AI-powered solutions for various industries. As the CEO, he is responsible for overseeing the company's operations, strategy, and growth. He has extensive experience in the technology industry and has held leadership roles in several other companies. At AI Planet, he aims to leverage the power of AI to transform businesses and improve people's lives.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":[],"metadata":{"id":"HOfyPYj0unsp"},"execution_count":null,"outputs":[]}]}